{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from constants import data_dir\n",
    "from splice_dataset import SpliceDataset\n",
    "from splice_ai_torch import SpliceAI, categorical_crossentropy_2d\n",
    "from utils import get_architecture, SL\n",
    "\n",
    "from spliceai import SpliceAI as SpliceAIOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "CL, N_GPUS = 80, 1\n",
    "L = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "W, AR, BATCH_SIZE = get_architecture(CL, N_GPUS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_old = SpliceAIOld(L, W, AR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 32)     160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 32)     128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 32)     11296       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 32)     128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 32)     11296       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 32)     0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 32)     128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 32)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 32)     11296       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 32)     128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 32)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 32)     11296       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 32)     0           conv1d_5[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 32)     128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 32)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 32)     11296       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 32)     128         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 32)     11296       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 32)     0           conv1d_7[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, 32)     128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, 32)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 32)     11296       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, 32)     128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 32)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 32)     11296       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, 32)     0           conv1d_9[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 32)     1056        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 32)     1056        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, 32)     0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d (Cropping1D)         (None, None, 32)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 3)      99          cropping1d[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 93,763\n",
      "Trainable params: 93,251\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_old.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [18, 32, 5080]             160\n",
      "            Conv1d-2             [18, 32, 5080]           1,056\n",
      "       BatchNorm1d-3             [18, 32, 5080]              64\n",
      "              ReLU-4             [18, 32, 5080]               0\n",
      "            Conv1d-5             [18, 32, 5080]          11,296\n",
      "       BatchNorm1d-6             [18, 32, 5080]              64\n",
      "              ReLU-7             [18, 32, 5080]               0\n",
      "            Conv1d-8             [18, 32, 5080]          11,296\n",
      "       BatchNorm1d-9             [18, 32, 5080]              64\n",
      "             ReLU-10             [18, 32, 5080]               0\n",
      "           Conv1d-11             [18, 32, 5080]          11,296\n",
      "      BatchNorm1d-12             [18, 32, 5080]              64\n",
      "             ReLU-13             [18, 32, 5080]               0\n",
      "           Conv1d-14             [18, 32, 5080]          11,296\n",
      "      BatchNorm1d-15             [18, 32, 5080]              64\n",
      "             ReLU-16             [18, 32, 5080]               0\n",
      "           Conv1d-17             [18, 32, 5080]          11,296\n",
      "      BatchNorm1d-18             [18, 32, 5080]              64\n",
      "             ReLU-19             [18, 32, 5080]               0\n",
      "           Conv1d-20             [18, 32, 5080]          11,296\n",
      "      BatchNorm1d-21             [18, 32, 5080]              64\n",
      "             ReLU-22             [18, 32, 5080]               0\n",
      "           Conv1d-23             [18, 32, 5080]          11,296\n",
      "      BatchNorm1d-24             [18, 32, 5080]              64\n",
      "             ReLU-25             [18, 32, 5080]               0\n",
      "           Conv1d-26             [18, 32, 5080]          11,296\n",
      "           Conv1d-27             [18, 32, 5080]           1,056\n",
      "           Conv1d-28              [18, 3, 5000]              99\n",
      "          Softmax-29              [18, 3, 5000]               0\n",
      "================================================================\n",
      "Total params: 93,251\n",
      "Trainable params: 93,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.40\n",
      "Forward/backward pass size (MB): 606.87\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 608.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SpliceAI(L, W, AR).to(device)\n",
    "summary(model, input_size=(4, CL + SL), batch_size=BATCH_SIZE)\n",
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "h5f = h5py.File(data_dir + 'dataset_train_all.h5', 'r')\n",
    "\n",
    "num_idx = len(h5f.keys()) // 2\n",
    "idx_all = np.random.permutation(num_idx)\n",
    "idx_train = idx_all[:int(0.9 * num_idx)]\n",
    "idx_valid = idx_all[int(0.9 * num_idx):]\n",
    "\n",
    "EPOCH_NUM = 10 * len(idx_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch number 0 / 1190.\n",
      "loss: 1.642687\n",
      "On epoch number 1 / 1190.\n",
      "loss: 1.093218\n",
      "On epoch number 2 / 1190.\n",
      "loss: 0.014481\n",
      "On epoch number 3 / 1190.\n",
      "loss: 0.568272\n",
      "On epoch number 4 / 1190.\n",
      "loss: 0.387847\n",
      "On epoch number 5 / 1190.\n",
      "loss: 0.016746\n",
      "On epoch number 6 / 1190.\n",
      "loss: 0.180956\n",
      "On epoch number 7 / 1190.\n",
      "loss: 0.505524\n",
      "On epoch number 8 / 1190.\n",
      "loss: 0.229167\n",
      "On epoch number 9 / 1190.\n",
      "loss: 0.311344\n",
      "On epoch number 10 / 1190.\n",
      "loss: 0.547637\n",
      "On epoch number 11 / 1190.\n",
      "loss: 0.199852\n",
      "On epoch number 12 / 1190.\n",
      "loss: 0.170929\n",
      "On epoch number 13 / 1190.\n",
      "loss: 0.400041\n",
      "On epoch number 14 / 1190.\n",
      "loss: 0.011400\n",
      "On epoch number 15 / 1190.\n",
      "loss: 0.000982\n",
      "On epoch number 16 / 1190.\n",
      "loss: 0.557901\n",
      "On epoch number 17 / 1190.\n",
      "loss: 0.738615\n",
      "On epoch number 18 / 1190.\n",
      "loss: 0.203652\n",
      "On epoch number 19 / 1190.\n",
      "loss: 0.390415\n",
      "On epoch number 20 / 1190.\n",
      "loss: 0.537605\n",
      "On epoch number 21 / 1190.\n",
      "loss: 0.366669\n",
      "On epoch number 22 / 1190.\n",
      "loss: 0.179722\n",
      "On epoch number 23 / 1190.\n",
      "loss: 0.029848\n",
      "On epoch number 24 / 1190.\n",
      "loss: 0.927375\n",
      "On epoch number 25 / 1190.\n",
      "loss: 0.016656\n",
      "On epoch number 26 / 1190.\n",
      "loss: 0.133276\n",
      "On epoch number 27 / 1190.\n",
      "loss: 0.027299\n",
      "On epoch number 28 / 1190.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_169495/2083419461.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0mfull_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0;31m# if loss.item() > 0.4 and epoch_num > 0:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch_num in range(EPOCH_NUM):\n",
    "\n",
    "    print(f'On epoch number {epoch_num} / {EPOCH_NUM}.')\n",
    "\n",
    "    idx = np.random.choice(idx_train)\n",
    "\n",
    "    X = h5f['X' + str(idx)][:]\n",
    "    Y = np.asarray(h5f['Y' + str(idx)][:], dtype=np.float32)\n",
    "\n",
    "    splice_dataset = SpliceDataset(X, Y, CL, N_GPUS)\n",
    "\n",
    "    dataloader = DataLoader(splice_dataset, batch_size=BATCH_SIZE)\n",
    "    full_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = categorical_crossentropy_2d(y, pred)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        full_loss += loss.item()\n",
    "\n",
    "        # if loss.item() > 0.4 and epoch_num > 0:\n",
    "        #     break\n",
    "        #\n",
    "        # if any([y[i].sum(axis=(1,))[0] < y[i].shape[-1] for i in range(y.shape[0])]) and epoch_num > 32:\n",
    "        #     break\n",
    "    else:\n",
    "        print(f\"loss: {full_loss:>7f}\")\n",
    "        continue\n",
    "    break\n",
    "\n",
    "h5f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([18, 3, 5000])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 5000])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4.9999e+03, 3.8468e-02, 5.8596e-02], device='cuda:0',\n       grad_fn=<SumBackward1>)"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].sum(axis=(1,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4988.,    7.,    5.], device='cuda:0')"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].sum(axis=(1,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0., device='cuda:0', grad_fn=<NegBackward>)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_crossentropy_2d(y, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "80"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 5080, 4)\n",
      "0\n",
      "0\n",
      "(668, 5080, 4)\n",
      "(668, 4, 5080)\n"
     ]
    }
   ],
   "source": [
    "X = h5f['X' + str(idx)][:]\n",
    "Y = np.asarray(h5f['Y' + str(idx)][:], dtype=np.float32)\n",
    "\n",
    "splice_dataset = SpliceDataset(X, Y, CL, N_GPUS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "(668, 4, 5080)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splice_dataset.X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([], device='cuda:0', size=(4, 0)),\n tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'))"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splice_dataset[34]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "(2500, 5080, 4)"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f['X' + str(idx)][:].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_169495/112612406.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([18, 4, 0])"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(71945., device='cuda:0')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=(0, 2,))[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor(4992., device='cuda:0'),\n tensor(4996., device='cuda:0'),\n tensor(4997., device='cuda:0'),\n tensor(4992., device='cuda:0'),\n tensor(1960., device='cuda:0'),\n tensor(4991., device='cuda:0'),\n tensor(5000., device='cuda:0'),\n tensor(4995., device='cuda:0'),\n tensor(3104., device='cuda:0'),\n tensor(4998., device='cuda:0'),\n tensor(4998., device='cuda:0'),\n tensor(4997., device='cuda:0'),\n tensor(4996., device='cuda:0'),\n tensor(4994., device='cuda:0'),\n tensor(4999., device='cuda:0'),\n tensor(4993., device='cuda:0'),\n tensor(4996., device='cuda:0'),\n tensor(4998., device='cuda:0')]"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y[i].sum(axis=(1,))[0].data for i in range(y.shape[0])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "[torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000]),\n torch.Size([3, 5000])]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y[i].shape for i in range(y.shape[0])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True, device='cuda:0')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-1].sum(axis=(1,))[0] < y[-1].shape[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([y[i].sum(axis=(1,))[0] < y[i].shape[-1] for i in range(y.shape[0])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 1855, 5000, 3)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import wandb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33manej\u001B[0m (use `wandb login --relogin` to force relogin)\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}